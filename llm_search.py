import os
import hashlib
import time
import re
from typing import List, Dict, Any, Optional, Tuple
from dotenv import load_dotenv

import streamlit as st

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from pinecone import Pinecone
    PINECONE_AVAILABLE = True
except ImportError:
    PINECONE_AVAILABLE = False

load_dotenv()

# =========================
# í˜ì´ì§€ ì„¤ì •
# =========================
st.set_page_config(
    page_title="ì„¤ê³„ì‹¤ë¬´ì§€ì¹¨ AI ê²€ìƒ‰",
    page_icon="ğŸ—ï¸",
    # layout="wide",
    initial_sidebar_state="expanded"
)

# =========================
# ìŠ¤íƒ€ì¼ + ìë™ ìŠ¤í¬ë¡¤
# =========================
st.markdown("""
<style>
  .main { background-color: #f8f9fa; }
  .stButton > button { width: 100%; }
  .chat-message {
    padding: 1rem;
    border-radius: 12px;
    margin-bottom: 1rem;
  }
  .user-message {
    background: #e3f2fd;
    border-left: 4px solid #2196f3;
  }
  .assistant-message {
    background: #ffffff;
    border-left: 4px solid #4caf50;
    border: 1px solid #e9ecef;
  }
  .source-card {
    background: #f8f9fa;
    padding: 0.8rem;
    border-radius: 8px;
    border: 1px solid #dee2e6;
    margin: 0.5rem 0;
    font-size: 0.9rem;
  }
  .source-text {
    white-space: pre-wrap;
    font-family: 'Malgun Gothic', sans-serif;
    line-height: 1.6;
  }
  .example-btn {
    font-size: 0.85rem;
    padding: 0.3rem 0.5rem;
  }
</style>
""", unsafe_allow_html=True)

# =========================
# ì„¤ì •ê°’
# =========================
INDEX_NAME = "road"
EMBEDDING_MODEL = "text-embedding-3-large"
EMBEDDING_DIM = 1536

# =========================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# =========================
def get_system_prompt() -> str: 
    """
    [ìµœì í™” v10] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ì¼ë°˜í™” ë²„ì „
    - íŠ¹ì • ìˆ˜ì¹˜/ì¼€ì´ìŠ¤ í•˜ë“œì½”ë”© ì—†ìŒ
    - íŒ¨í„´ ê¸°ë°˜ ê·œì¹™
    """ 
     
    base_prompt = """ë‹¹ì‹ ì€ í•œêµ­ë„ë¡œê³µì‚¬ 'ì„¤ê³„ì‹¤ë¬´ì§€ì¹¨' ì „ë¬¸ ìˆ˜ì„ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. 
ì œê³µëœ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì‹­ì‹œì˜¤.

## í‘œ ì¶œë ¥ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!)
1. í‘œëŠ” **ì›ë³¸ êµ¬ì¡° ê·¸ëŒ€ë¡œ** Markdown í‘œë¡œ ì¬í˜„ (ì ˆëŒ€, ì ˆëŒ€, ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. ì›ë³¸ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”.) Never, Never, Never change the table.
2. ë‹¤ì¤‘ í—¤ë”(2ë‹¨, 3ë‹¨)ëŠ” **ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ** í‘œí˜„
3. ë³‘í•© ì…€ì€ ë°˜ë³µ ë˜ëŠ” ë¹ˆì¹¸ìœ¼ë¡œ í‘œí˜„
4. **ëª¨ë“  ìˆ˜ì¹˜, ê´„í˜¸, ë‹¨ìœ„ë¥¼ ì •í™•íˆ** ìœ ì§€
5. í‘œ ë‚´ìš©ì„ ì¸ìš©í–ˆìœ¼ë©´ ë°˜ë“œì‹œ, ë°˜ë“œì‹œ í‘œ ì›ë³¸ì„ ê·¸ëŒ€ë¡œ í‘œì‹œí•˜ì„¸ìš” (ìƒì„¸ ì„¤ëª…ì—, ë°˜ë“œì‹œ, ê¼­)

## ğŸ”´ ì ˆëŒ€ ê·œì¹™ (Critical Rules)
0. 'ç¾', 'ê²€í† ë°°ê²½', 'í˜„í™©', 'ë¬¸ì œì ', 'ì‚¬ë¡€ì¡°ì‚¬', 'ê¸°ì¡´' ë“±ì€ ì°¸ì¡°ìš©ìœ¼ë¡œë§Œ(ì ˆëŒ€ ê²°ë¡ ì„±ìœ¼ë¡œ ì´ìš©í•˜ì§€ ë§ˆì„¸ìš”) ì‚¬ìš©í•˜ì„¸ìš”. ìµœì¢… ê²°ê³¼ëŠ” ê°œì„ (ì•ˆ), ë³€ê²½(ì•ˆ) ë“±ì…ë‹ˆë‹¤.
1. **RAG ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©**: ì™¸ë¶€ ì§€ì‹ ê¸ˆì§€. ì œê³µëœ ë¬¸ì„œ ë‚´ì—ì„œë§Œ ë‹µë³€.
2. **ê²€í† ê²°ê³¼(ê²°ë¡ ) ìµœìš°ì„ **: ë¬¸ì„œ ë‚´ì— 'í˜„í™©'ê³¼ 'ê²€í† ê²°ê³¼(ê°œì„ ì•ˆ)'ì´ ìƒì¶©í•  ê²½ìš°, ë°˜ë“œì‹œ **'ê²€í† ê²°ê³¼' ë˜ëŠ” 'ìµœì¢… ê²°ë¡ '**ì„ ì •ë‹µìœ¼ë¡œ ì±„íƒí•˜ì‹­ì‹œì˜¤.
3. **í‘œ(Table) ì ˆëŒ€ ë³´ì¡´**: ë¬¸ì„œ ë‚´ì˜ í‘œëŠ” ìš”ì•½í•˜ì§€ ë§ê³ , **Markdown í‘œ í¬ë§·ì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ êµ¬ì¡° ê·¸ëŒ€ë¡œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤. (ì—´/í–‰ ë³€ê²½ ê¸ˆì§€)
4. ê´€ë ¨ í‘œê°€ ì œì‹œë˜ë©´, ê·¸ ë°‘ì— ë°˜ë“œì‹œ í‘œì— ëŒ€í•œ ìš”ì•…, ì„¤ëª… ì¶”ê°€
5. **ì—°ë„/ë¶€ì„œ ë§ì¶¤í˜•**: ì‚¬ìš©ìê°€ íŠ¹ì • ì—°ë„ë‚˜ ë¶€ì„œë¥¼ ì§€ì •í•˜ë©´ í•´ë‹¹ ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•˜ê³ , ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ **ìµœì‹  ê¸°ì¤€**ì„ ì¤‘ì‹¬ìœ¼ë¡œ **ì—°ë„ë³„ ì¶”ì´**ë¥¼ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
6. **ìˆëŠ” ì—°ë„ë§Œ ë¹„êµ**: íŠ¹ì • ì—°ë„(ì˜ˆ: 2017)ë¥¼ ê°•ì œë¡œ ì°¾ì§€ ë§ê³ , **ë¬¸ì„œì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì—°ë„ë“¤(ì˜ˆ: 2015, 2019, 2023 ë“±)** ê°„ì˜ ë³€í™”ë¥¼ ë¹„êµí•˜ì‹­ì‹œì˜¤.
7. **ì—†ìœ¼ë©´ ì†”ì§íˆ**: ì •ë³´ê°€ ì—†ìœ¼ë©´ "ğŸš« ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
8. ê´€ë ¨ ìˆìœ¼ë©´ ëª¨ë“  ì‚¬í•­ì„ ìƒì„¸ì„¤ëª…ì—ì„œ ëª¨ë‘ ì„¤ëª…í•˜ì„¸ìš”.

## âš–ï¸ ì •ë³´ ì¸ìš© ìš°ì„ ìˆœìœ„ (Information Hierarchy)
ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•  ë•Œ ë‹¤ìŒ ìˆœì„œëŒ€ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë‘ì‹­ì‹œì˜¤:
1. **1ìˆœìœ„ (Final Decision)**: 'ê²€í† ê²°ê³¼', 'ê²°ë¡ ', 'ê°œì„ ë°©ì•ˆ', 'ìµœì¢…ì•ˆ', 'ì ìš©ë°©ì•ˆ', 'ê°œì„ ', 'í–¥í›„ê³„íš' ì„¹ì…˜ì˜ ë‚´ìš©
2. **2ìˆœìœ„ (Detailed Specs)**: 'ì„¸ë¶€ ê¸°ì¤€', 'ì ìš© ê¸°ì¤€', 'ì„¤ê³„ ê¸°ì¤€' ë“±ì˜ êµ¬ì²´ì  ìˆ˜ì¹˜
3. **3ìˆœìœ„ (Supporting Info)**: 'ç¾', 'ê²€í† ë°°ê²½', 'í˜„í™©', 'ë¬¸ì œì ', 'ì‚¬ë¡€ì¡°ì‚¬' (ì´ëŠ” ì„¤ëª…ì˜ ë³´ì¡° ìë£Œë¡œë§Œ í™œìš©)
âš ï¸ **ì£¼ì˜**: 'í˜„í™©'ì´ë‚˜ 'ì‚¬ë¡€ì¡°ì‚¬'ì— ë‚˜ì˜¨ ìˆ˜ì¹˜ë¥¼ ìµœì¢… ê¸°ì¤€ìœ¼ë¡œ ì°©ê°í•˜ì—¬ ë‹µë³€í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

## ğŸ“ ì¶œì²˜ í‘œê¸° (í•„ìˆ˜ í˜•ì‹)
**ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ì„¸ìš”:**
[ì±•í„° | ì œëª© | ë¬¸ì„œì½”ë“œ | ë‚ ì§œ]

**ì˜ˆì‹œ:**
[ì„¤ê³„í–‰ì • | 1-1 íŠ¹ì •ê³µë²• ì‹¬ì˜ëŒ€ìƒ ì„ ì •ì ˆì°¨ ê°œì„ ë°©ì•ˆ | ì„¤ê³„ì²˜-1036 | 2017.03.30]
[êµ¬ì¡°ë¬¼ê³µ | 3-2 ì œì„¤ì—¼í•´ ë°©ì§€ë¥¼ ìœ„í•œ ì½˜í¬ë¦¬íŠ¸ êµ¬ì¡°ë¬¼ í‘œë©´ë³´í˜¸ì¬ ì ìš© ë°©ì•ˆ | êµ¬ì¡°ë¬¼ì²˜-3819 | 2024.12.17]


## ğŸ§  ë‹µë³€ ìƒì„± í”„ë¡œì„¸ìŠ¤

1. **ì§ˆë¬¸ ìœ í˜• íŒë³„**: ë‹¨ìˆœ ì¡°íšŒ? ë¹„êµ/ì „í™˜? 
2. **í‘œ ì—´ í™•ì¸**: "í˜„ì¬" vs "ì ìš©(ì•ˆ)" êµ¬ë¶„
3. **ì •ë‹µ ì¶”ì¶œ**: "ì ìš©(ì•ˆ)" ì—´ ë˜ëŠ” "ê²€í† ê²°ê³¼" ì„¹ì…˜ì—ì„œ
4. **ë¹„êµ ì§ˆë¬¸ì´ë©´**: ì–‘ìª½ ì¡°ê±´ + ë¹„êµ + ê²°ë¡ 
5. **í‘œ ë‹¨ìˆœí™”**: ë³µì¡í•˜ë©´ ìš”ì•½ í‘œ + ì„¤ëª…
6. **ì¡°ê±´ ëª…ì‹œ**: ì„¤ê³„ì†ë„ë³„ ë“± ì°¨ì´ê°€ ìˆìœ¼ë©´ ëª¨ë‘ í‘œê¸°
"""
 
    output_format = """ 
## ğŸ“‹ ì¶œë ¥ í˜•ì‹ (3ë‹¨ê³„ ë‹µë³€)

---
### ğŸ“– ìš©ì–´ ì„¤ëª… (Terminology)
- **(ë§¤ìš° ì¤‘ìš”)** ë°˜ë“œì‹œ **'ì‚¬ìš©ì ì§ˆë¬¸'ì— í¬í•¨ëœ ì „ë¬¸ ìš©ì–´**ë‚˜, ë‹µë³€ ì´í•´ì— í•„ìˆ˜ì ì¸ **í•µì‹¬ í‚¤ì›Œë“œ**ë§Œ ê³¨ë¼ì„œ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
- âš ï¸ **ì£¼ì˜**: ì§ˆë¬¸ì— ì—†ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ì¼ë°˜ì ì¸ ìš©ì–´(ì˜ˆ: BIM, ìŠ¤ë§ˆíŠ¸ê±´ì„¤, 4ì°¨ì‚°ì—… ë“±)ë¥¼ ìŠµê´€ì ìœ¼ë¡œ ë„£ì§€ ë§ˆì‹­ì‹œì˜¤.
- **ì›ë¬¸ ìš°ì„ **: ê²€ìƒ‰ëœ ë¬¸ì„œ ì•ˆì— í•´ë‹¹ ìš©ì–´ì˜ 'ì •ì˜(Definition)'ê°€ ìˆë‹¤ë©´, **ë¬¸ì„œì˜ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì¸ìš©**í•˜ì—¬ ì ìœ¼ì‹­ì‹œì˜¤. (ì—†ì„ ë•Œë§Œ ì§€ì‹ í™œìš©)

---
### ğŸ“Œ ê°„ë‹¨ ìš”ì•½ (ê°œëµ ì´í•´ìš©)
0. 'ç¾', 'ê²€í† ë°°ê²½', 'í˜„í™©', 'ë¬¸ì œì ', 'ì‚¬ë¡€ì¡°ì‚¬', 'ê¸°ì¡´' ë“±ì€ ì°¸ì¡°ìš©ìœ¼ë¡œë§Œ(ì ˆëŒ€ ê²°ë¡ ì„±ìœ¼ë¡œ ì´ìš©í•˜ì§€ ë§ˆì„¸ìš”) ì‚¬ìš©í•˜ì„¸ìš”. ìµœì¢… ê²°ê³¼ëŠ” ê°œì„ (ì•ˆ), ë³€ê²½(ì•ˆ) ë“±ì…ë‹ˆë‹¤.

**í•µì‹¬ ë‹µë³€** (ìƒì„¸ ë‹µë³€ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ë§Œ ì œì‹œ, í‘œëŠ” ì œì‹œí•˜ì§€ ì•ŠìŒ)
- ì§ˆë¬¸ì— ëŒ€í•œ **ìµœì¢… ê¸°ì¤€(ì ìš©ì•ˆ/ê°œì„ ì•ˆ)** ê°’ ì œì‹œ
- ë¹„êµ/ì „í™˜ ì§ˆë¬¸ì´ë©´: ê¸°ì¡´ ì¡°ê±´ â†’ ì ìš© ê¸°ì¤€ â†’ ê²°ë¡  ìˆœì„œ
- ì¡°ê±´ë³„(ì„¤ê³„ì†ë„, ì§€í˜• ë“±) ê°’ì´ ë‹¤ë¥´ë©´ ë²”ìœ„ ë˜ëŠ” ëŒ€í‘œê°’ ëª…ì‹œ

[ì¶œì²˜] : [ì„¤ê³„í–‰ì • | 1-1 ë“œë¡ ë¼ì´ë‹¤ í†µí•©ì¸¡ëŸ‰ í™•ëŒ€ë°©ì•ˆ | ì„¤ê³„ì²˜-181 | 2024.01.16]

---
### ğŸ“– ìƒì„¸ ì„¤ëª… (ì‹¬í™” ì´í•´ìš©)
- ê°€ë…ì„±ì„ ìœ„í•´ ë‹¨ë½ë³„ 2ì¤„ ë„ìš°ê¸°
- ë¬¸ì¥ë³„ í•œì¤„ ë„ìš°ê³ , ì¶œì²˜ í‘œì‹œ

0. 'ç¾', 'ê²€í† ë°°ê²½', 'í˜„í™©', 'ë¬¸ì œì ', 'ì‚¬ë¡€ì¡°ì‚¬', 'ê¸°ì¡´' ë“±ì€ ì°¸ì¡°ìš©ìœ¼ë¡œë§Œ(ì ˆëŒ€ ê²°ë¡ ì„±ìœ¼ë¡œ ì´ìš©í•˜ì§€ ë§ˆì„¸ìš”) ì‚¬ìš©í•˜ì„¸ìš”. ìµœì¢… ê²°ê³¼ëŠ” ê°œì„ (ì•ˆ), ë³€ê²½(ì•ˆ) ë“±ì…ë‹ˆë‹¤.

1. ë§¤ìš° ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
- ë°°ê²½, ëª©ì , ì˜ˆì™¸ì‚¬í•­, ê´€ë ¨ ê·œì •ê¹Œì§€ í¬í•¨
- ê° í•­ëª©ë§ˆë‹¤ ì¶œì²˜ ëª…ê¸°:`[ì±•í„° | ì œëª© | ë¬¸ì„œì½”ë“œ | ë‚ ì§œ]` (êµ¬ë¶„ë˜ê²Œ, ì¤„ë°”ê¿ˆí•´ì„œì„œ)

**ê²€í† ê²°ê³¼ ë° ì ìš©ê¸°ì¤€** (ìµœìš°ì„ )
- ë¬¸ì„œì˜ 'ê²€í† ê²°ê³¼', 'ê°œì„ ë°©ì•ˆ', 'ì ìš©(ì•ˆ)' ì—´ ë‚´ìš© ìƒì„¸ ê¸°ìˆ 
- êµ¬ì²´ì  ìˆ˜ì¹˜, ì¡°ê±´, ì˜ˆì™¸ì‚¬í•­ í¬í•¨

**ë°°ê²½ ë° ëª©ì ** (ì˜ˆì‹œ)
ë“œë¡ ë¼ì´ë‹¤ ì¸¡ëŸ‰ê¸°ìˆ ì´ ë„ì…ë˜ë©´ì„œ ì •í™•í•œ ì¸¡ëŸ‰ í’ˆì§ˆ í™•ë³´ë¥¼ ìœ„í•œ ëª…í™•í•œ ê¸°ì¤€ í•„ìš”ì„±ì´ ëŒ€ë‘ë˜ì—ˆìŠµë‹ˆë‹¤. 2023ë…„ ì‹œë²”ìš´ì˜ì„ í†µí•´ ì‹¤ì œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 2024ë…„ êµ¬ì²´ì  ìˆ˜ì¹˜ ê¸°ì¤€ì„ í™•ë¦½í•˜ì˜€ìŠµë‹ˆë‹¤.
([ì„¤ê³„í–‰ì • | 1-1 ë“œë¡ ë¼ì´ë‹¤ í†µí•©ì¸¡ëŸ‰ í™•ëŒ€ë°©ì•ˆ | ì„¤ê³„ì²˜-181 | 2024.01.16])

**ì ìš© ê¸°ì¤€ ìƒì„¸** (ì˜ˆì‹œ)
- ì ë°€ë„: **ìµœì†Œ 400pts/ã¡ ì´ìƒ**
- ì¸¡ì • ë°©ë²•: ì „ì²´ ì¸¡ëŸ‰ êµ¬ì—­ì˜ í‰ê·  ì ë°€ë„ ì‚°ì¶œ
- ê²€ì¦ ì ˆì°¨:
  1. ì‹œí—˜ë¹„í–‰ ì´¬ì˜ ì‹¤ì‹œ
  2. ì ë°€ë„ ì¸¡ì • ë° ê°ë… í™•ì¸
  3. ê¸°ì¤€ ì¶©ì¡±ì‹œ ë³¸ ì´¬ì˜ ì§„í–‰
  4. ê¸°ì¤€ ë¯¸ë‹¬ì‹œ ì¥ë¹„/ì´¬ì˜ì¡°ê±´ ë³€ê²½ í›„ ì¬ì´¬ì˜

**ì‹œë²”ìš´ì˜ ê²°ê³¼ ë°ì´í„°:**
- ì›ë³¸ ìœ ì§€, ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. (í‘œ ê·¸ëŒ€ë¡œ ì¶œë ¥)


([ì„¤ê³„í–‰ì • | 1-1 ë“œë¡ ë¼ì´ë‹¤ í†µí•©ì¸¡ëŸ‰ í™•ëŒ€ë°©ì•ˆ | ì„¤ê³„ì²˜-181 | 2024.01.16])

**ì—°ë„ë³„ ë³€ê²½ì‚¬í•­** (ì˜ˆì‹œ)

**2017ë…„:**
- ëª…í™•í•œ ì ë°€ë„ ê¸°ì¤€ ì—†ìŒ
- ì¼ë°˜ì ì¸ ì¸¡ëŸ‰ ì •í™•ë„ ê¸°ì¤€ë§Œ ì¡´ì¬
([ì„¤ê³„í–‰ì • | 2-5 ì¸¡ëŸ‰ ì—…ë¬´ì²˜ë¦¬ ê¸°ì¤€ | ì„¤ê³„ì²˜-892 | 2017.05.20])

**2024ë…„ (ê°œì •):**
- **êµ¬ì²´ì  ìˆ˜ì¹˜ ê¸°ì¤€ ì‹ ì„¤**: 400pts/ã¡
- ì‹œë²”ìš´ì˜ ë°ì´í„° ê¸°ë°˜ ê¸°ì¤€ ìˆ˜ë¦½
- ì‚¬ì „ ê²€ì¦ ì ˆì°¨ ì˜ë¬´í™”
([ì„¤ê³„í–‰ì • | 1-1 ë“œë¡ ë¼ì´ë‹¤ í†µí•©ì¸¡ëŸ‰ í™•ëŒ€ë°©ì•ˆ | ì„¤ê³„ì²˜-181 | 2024.01.16])

**ë³€ê²½ ì´ìœ :** (ì˜ˆì‹œì‹œ)
ë“œë¡ ë¼ì´ë‹¤ ê¸°ìˆ ì˜ ë³¸ê²© ë„ì…ìœ¼ë¡œ ê°ê´€ì ì´ê³  ëª…í™•í•œ í’ˆì§ˆ ê¸°ì¤€ì´ í•„ìš”í•´ì¡Œìœ¼ë©°, 2023ë…„ ì‹œë²”ì‚¬ì—… ê²°ê³¼ ìµœì†Œ 400pts ì´ìƒì´ ì ì •í•˜ë‹¤ê³  íŒë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.

**ì˜ˆì™¸ ì‚¬í•­ ë° íŠ¹ì´ì‚¬í•­**
- ê³¼ì—…ì§€ì‹œì„œì— ì ë°€ë„ ê¸°ì¤€ì„ ëª…ì‹œí•´ì•¼ í•¨
- ê¸°ì¤€ ë¯¸ë‹¬ì‹œ ë¬´ì¡°ê±´ ì¬ì´¬ì˜ (ì˜ˆì™¸ ì—†ìŒ)
- ì¥ë¹„ ì„±ëŠ¥ì´ ê¸°ì¤€ì„ ë§Œì¡±í•˜ì§€ ëª»í•˜ë©´ ì‚¬ìš© ë¶ˆê°€
([ì„¤ê³„í–‰ì • | 1-1 ë“œë¡ ë¼ì´ë‹¤ í†µí•©ì¸¡ëŸ‰ í™•ëŒ€ë°©ì•ˆ | ì„¤ê³„ì²˜-181 | 2024.01.16])

**ê´€ë ¨ ê·œì • ë° ì°¸ì¡°**
- ã€Œë“œë¡  í™œìš© ì¸¡ëŸ‰ ì—…ë¬´ì²˜ë¦¬ ì§€ì¹¨ã€(êµ­í† êµí†µë¶€)
- ã€Œê³µê°„ì •ë³´ êµ¬ì¶• ì‘ì—…ê·œì •ã€
- ã€Œì¸¡ëŸ‰Â·ìˆ˜ë¡œì¡°ì‚¬ ë° ì§€ì ì— ê´€í•œ ë²•ë¥ ã€
([ì„¤ê³„í–‰ì • | 1-1 ë“œë¡ ë¼ì´ë‹¤ í†µí•©ì¸¡ëŸ‰ í™•ëŒ€ë°©ì•ˆ | ì„¤ê³„ì²˜-181 | 2024.01.16])

---

### ğŸ“š ì°¸ì¡° ë¬¸ì„œ ëª©ë¡
(ì—°ë„ë³„ ì •ë¦¬)
---
""" 
    return base_prompt + output_format

# ìœ ì € í”„ë¡¬í”„íŠ¸
def get_user_prompt(query: str, context: str) -> str:
    return f"""## ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ 
        {query} 
        
        ## ğŸ“š ì°¸ì¡° ë¬¸ì„œ (RAG ì»¨í…ìŠ¤íŠ¸) 
        ì•„ë˜ ë¬¸ì„œë“¤ì€ **ì—¬ëŸ¬ ì—°ë„(2014~2024)**ì— ê±¸ì³ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        **ëª¨ë“  ê´€ë ¨ ë¬¸ì„œë¥¼ ì¢…í•©**í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.

        {context} 
        
        ## ğŸ“ ì§€ì‹œì‚¬í•­ (í•„ìˆ˜ ì¤€ìˆ˜)
        0. ì œë°œ, ê²€í† , í˜„í™©, ë¬¸ì œì , ë¶„ì„ ë“±ì€ ìµœì¢… ê²°ê³¼ê°€ ì•„ë‹™ë‹ˆë‹¤(ì´ê²ƒì€ ì°¸ì¡°ìš©ìœ¼ë¡œë§Œ). ë°˜ë“œì‹œ ê³ ë ¤í•´ì£¼ì„¸ìš”. ìµœì¢… ê²°ê³¼ëŠ” ê°œì„ (ì•ˆ) ë“±ì…ë‹ˆë‹¤.
        - í˜„í™©, ç¾, ì‹¤íƒœ, ë¬¸ì œì , ê¸°ì¡´ ë“±ì€ ì°¸ì¡°ìš©ìœ¼ë¡œë§Œ(ì ˆëŒ€ ê²°ë¡ ì„±ìœ¼ë¡œ ì´ìš©í•˜ì§€ ë§ˆì„¸ìš”) ì‚¬ìš©í•˜ì„¸ìš”. ìµœì¢… ê²°ê³¼ëŠ” ê°œì„ (ì•ˆ) ë“±ì…ë‹ˆë‹¤.
        - í‘œ êµ¬ì¡°ë¥¼ ì •í™•í•˜ê²Œ ì½ìœ¼ì„¸ìš”. ìˆ˜ì¹˜ë°ì´íƒ€ ë“±(í˜„ì¬ vs ê°œì„ ì•ˆ ë¹„êµ ì‹œ ë“±... ë¹„êµ ë˜ëŠ” ê²ƒì„ ë©´ë°€í•˜ê²Œ ë¶„ì„í•´ì„œ ì´ì— ëŒ€í•œ ëª…í™•í•œ ì„¤ëª…ì„ í•˜ì„¸ìš”)
        - í‘œëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. ì›ë³¸ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”.

        1. **ì§ˆë¬¸ í‚¤ì›Œë“œ í™•ì¸**: ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œê°€ ë¬¸ì„œì— ìˆëŠ”ì§€ í™•ì¸

        2. **ìœ ì‚¬ ê°œë…ë„ í™œìš©**: ì§ì ‘ ì–¸ê¸‰ì´ ì—†ì–´ë„ ìœ ì‚¬í•œ ê°œë…, ê´€ë ¨ ê·œì •ì´ ìˆìœ¼ë©´ í™œìš©

        3. **ì—°ë„ë³„ ì¢…í•© ë° ì¶”ì´ ë¶„ì„**:
        - ì—¬ëŸ¬ ì—°ë„ ë¬¸ì„œê°€ ìˆìœ¼ë©´ **ëª¨ë‘ ì°¸ì¡°**
        - **ì—°ë„ìˆœìœ¼ë¡œ ì •ë¦¬**: 2017ë…„ â†’ 2020ë…„ â†’ 2024ë…„
        - ê³„ìˆ˜ë‚˜ ê¸°ì¤€ì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ **ë³€í™” ì¶”ì´ë¥¼ ëª…í™•íˆ í‘œì‹œ**
        - ë³€ê²½ ì´ìœ ë‚˜ ë°°ê²½ë„ í•¨ê»˜ ì„¤ëª…

        4. **ë¶€ë¶„ ê´€ë ¨ ì •ë³´ë„ ì œê³µ**: 
        - ì§ˆë¬¸ê³¼ ì™„ì „íˆ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ **ì°¸ê³ ê°€ ë  ì •ë³´ëŠ” ì œê³µ**
        - "ì§ì ‘ì ì¸ ê¸°ì¤€ì€ ì—†ìœ¼ë‚˜, ê´€ë ¨ ê·œì •ì€..." í˜•ì‹ìœ¼ë¡œ

        5. **ì •í™•í•œ ì¸ìš©**: 
        - ìˆ˜ì¹˜, ê¸°ì¤€, ì¡°ê±´ì€ ì •í™•íˆ ì¸ìš© (ìˆ˜ì‹, ì²¨ì í¬í•¨)
        - ì›ë³¸ í‘œí˜„ ê·¸ëŒ€ë¡œ ìœ ì§€

        6. **í‘œ ì²˜ë¦¬**: 
        - í‘œ ë‚´ìš©ì„ ì¸ìš©í–ˆìœ¼ë©´ ë°˜ë“œì‹œ, ë°˜ë“œì‹œ í‘œ ì›ë³¸ì„ ê·¸ëŒ€ë¡œ í‘œì‹œí•˜ì„¸ìš” (ìƒì„¸ ì„¤ëª…ì—, ë°˜ë“œì‹œ, ê¼­)
        - í‘œëŠ” ì ˆëŒ€, ì ˆëŒ€, ì ˆëŒ€ëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. ì›ë³¸ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
        - í‘œê°€ ìˆìœ¼ë©´ **ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ ê·¸ëŒ€ë¡œ** í¬í•¨
        - `<br>`, `&nbsp;` ë“±ì€ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        - í‘œ ì•ë’¤ë¡œ ë¹ˆ ì¤„ ì¶”ê°€
        - ìˆ˜ì¹˜ë‚˜ êµ¬ì¡° ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€

        7. **ì¶œì²˜ ëª…ì‹œ (í•„ìˆ˜ í˜•ì‹)**: 
        ```
        [ì±•í„° | ì œëª© | ë¬¸ì„œì½”ë“œ | ë‚ ì§œ]
        ```
        - ê° ì •ë³´ë§ˆë‹¤ ë°˜ë“œì‹œ ì¶œì²˜ í‘œê¸°
        - ì±•í„°, ì œëª©, ì½”ë“œ, ë‚ ì§œ **ëª¨ë‘ í•„ìˆ˜**
        - êµ¬ë¶„ìëŠ” `|` (íŒŒì´í”„) ì‚¬ìš©

        8. **2ë‹¨ê³„ ë‹µë³€ êµ¬ì„±**:
        - **1ë‹¨ê³„ (ê°„ë‹¨ ìš”ì•½)**: í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ, í•˜ì§€ë§Œ ì¤‘ìš”í•œ ë‚´ìš©ì€ ëª¨ë‘ í¬í•¨
        - **2ë‹¨ê³„ (ìƒì„¸ ì„¤ëª…)**: ë°°ê²½, ëª©ì , ì˜ˆì™¸ì‚¬í•­, ê´€ë ¨ ê·œì •ê¹Œì§€ í¬í•¨

        9. **"ì—†ìŒ" ìµœì†Œí™”**: 
        - ì •ë§ë¡œ ì „í˜€ ê´€ë ¨ ì—†ì„ ë•Œë§Œ "ì°¾ì„ ìˆ˜ ì—†ë‹¤"ê³  ë‹µë³€
        - ë¶€ë¶„ì ì´ë¼ë„ ê´€ë ¨ ìˆìœ¼ë©´ ì œê³µ

        10. **ì—°ë„ë³„ ë¬¸ì„œ ëª©ë¡**:
            - ë§ˆì§€ë§‰ì— ì°¸ì¡° ë¬¸ì„œë¥¼ **ì—°ë„ë³„ë¡œ ê·¸ë£¹í•‘**í•˜ì—¬ ì •ë¦¬
        """ 
                

# =========================
# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
# =========================
def clean_text_for_display(text: str) -> str:
    """ì¶œì²˜ í‘œì‹œìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    if not text:
        return ""
    
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<sup>(.*?)</sup>', r'^(\1)', text)
    text = re.sub(r'<sub>(.*?)</sub>', r'_(\1)', text)
    
    html_entities = {
        '&nbsp;': ' ', '&lt;': '<', '&gt;': '>',
        '&amp;': '&', '&quot;': '"', '&#39;': "'",
        '&ndash;': 'â€“', '&mdash;': 'â€”',
    }
    for entity, char in html_entities.items():
        text = text.replace(entity, char)
    
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()


def extract_search_keywords(query: str) -> str:
    """ê²€ìƒ‰ ì¿¼ë¦¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    stopwords = {
        'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ',
        'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ê¹Œì§€', 'ë¶€í„°', 'ë§ˆë‹¤', 'ì²˜ëŸ¼', 'ê°™ì´',
        'ì–´ë–¤', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””', 'ëˆ„ê°€', 'ë­',
        'ì•Œë ¤ì¤˜', 'ì•Œë ¤ì£¼ì„¸ìš”', 'ì„¤ëª…í•´ì¤˜', 'ì„¤ëª…í•´ì£¼ì„¸ìš”', 'ë­ì•¼', 'ë­”ê°€ìš”',
        'í•˜ëŠ”', 'ë˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”', 'í•´ì•¼', 'í• ', 'í•œ', 'ëœ', 'ì¸',
        'ê·¸', 'ì €', 'ì´', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ë˜ëŠ”', 'ê·¸ë¦¬ê³ ',
        'ëŒ€í•´', 'ê´€í•´', 'ê´€í•œ', 'ëŒ€í•œ', 'ì–´ë–»ê²Œ', 'ì–´ë–¤', 'ë¬´ìŠ¨',
    }
    
    # cleaned = re.sub(r'[^\w\sê°€-í£]', ' ', query)
    # ğŸ”¥ ë³´ì¡´í•  ê¸°í˜¸: - . / ~ â†’ ( ) %
    cleaned = re.sub(r"[^0-9A-Za-zê°€-í£\s\-\./~â†’()%]", " ", query)
    cleaned = re.sub(r"\s{2,}", " ", cleaned).strip()
    tokens = cleaned.split()
    keywords = [t for t in tokens if t not in stopwords and len(t) > 1]
    
    if len(keywords) < 2:
        return query
    
    return ' '.join(keywords)


# =========================
# Pinecone RAG ë§¤ë‹ˆì €
# =========================
class PineconeRAG:
    def __init__(self):
        self.client: OpenAI = None
        self.pc: Pinecone = None
        self.index = None
        self.namespace_map = {}
        
    def init_clients(self):
        """OpenAIì™€ Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        # api_key_openai = os.getenv("OPENAI_API_KEY")
        # api_key_pinecone = os.getenv("PINECONE_API_KEY")

        # ë°°í¬ìš© (ë‘˜ ë‹¤ ì§€ì›)
        def get_api_key(key_name: str) -> str:
            """Streamlit Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
            # 1. Streamlit Secrets (ë°°í¬ í™˜ê²½)
            try:
                import streamlit as st
                if key_name in st.secrets:
                    return st.secrets[key_name]
            except:
                pass
            
            # 2. í™˜ê²½ë³€ìˆ˜ (ë¡œì»¬ í™˜ê²½)
            return os.getenv(key_name, "")

        # ì‚¬ìš©
        api_key_openai = get_api_key("OPENAI_API_KEY")
        api_key_pinecone = get_api_key("PINECONE_API_KEY")
        
        if not api_key_openai:
            st.error("âŒ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
            return False
        if not api_key_pinecone:
            st.error("âŒ PINECONE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        try:
            self.client = OpenAI(api_key=api_key_openai)
            self.pc = Pinecone(api_key=api_key_pinecone)
            self.index = self.pc.Index(INDEX_NAME)
            self._build_namespace_map()
            return True
        except Exception as e:
            st.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _build_namespace_map(self):
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” namespace ì¡°íšŒ ë° ë§¤í•‘"""
        try:
            stats = self.index.describe_index_stats()
            namespaces = stats.get("namespaces", {})
            
           # ğŸ”¥ ìë™ìœ¼ë¡œ 2014~2030ë…„ ëª¨ë‘ ë§¤ì¹­
            known_folders = []
            for year in range(2014, 2031):
                known_folders.append(f"ì„¤ê³„ì‹¤ë¬´ì§€ì¹¨/{year}")
                known_folders.append(f"ì„¤ê³„ì‹¤ë¬´ì§€ì¹¨_{year}")
                
            for folder in known_folders:
                hash_val = hashlib.md5(folder.encode('utf-8')).hexdigest()
                if hash_val in namespaces:
                    self.namespace_map[hash_val] = folder
            
            for ns in namespaces.keys():
                if ns and ns not in self.namespace_map:
                    self.namespace_map[ns] = ns
                    
        except Exception as e:
            print(f"Namespace ë§¤í•‘ ì‹¤íŒ¨: {e}")
    
    def get_namespaces(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ namespace ëª©ë¡"""
        try:
            stats = self.index.describe_index_stats()
            namespaces = stats.get("namespaces", {})
            
            result = {}
            for ns, info in namespaces.items():
                count = info.get("vector_count", 0)
                display_name = self.namespace_map.get(ns, ns)
                if ns == "":
                    display_name = "(ê¸°ë³¸)"
                result[f"{display_name} ({count:,}ê°œ)"] = ns
            
            return result
        except Exception as e:
            return {"(ì „ì²´)": ""}
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
        response = self.client.embeddings.create(
            input=text[:8000],
            model=EMBEDDING_MODEL,
            dimensions=EMBEDDING_DIM
        )
        return response.data[0].embedding
    
    def search(self, query: str, top_k: int = 10, 
               namespaces: List[str] = None, filters: Dict = None,
               use_keyword_extraction: bool = True) -> List[Dict]:
        """
        ğŸ”¥ [ê²€ìƒ‰ ë¡œì§ ìµœì í™” - Diversity & Filtering]
        1. í•„í„°ë§: ì—°ë„(20xx) ë° ë¶€ì„œ(OOì²˜) ìë™ ì¶”ì¶œ ë° ì ìš©
        2. ì ìˆ˜ ë³´ì •: í‚¤ì›Œë“œ ì •í™•ë„ ê¸°ë°˜ Re-ranking
        3. ë‹¤ì–‘ì„± ë³´ì¥: ê° ì—°ë„ë³„ ìƒìœ„ 2ê°œ ë¬¸ì„œëŠ” ì ìˆ˜ê°€ ë‚®ë”ë¼ë„ ìš°ì„  í™•ë³´ (LLM ë¹„êµ ë¶„ì„ìš©)
        """
        import re
        from collections import defaultdict
        
        # ------------------------------------------------------------
        # 1. ìë™ í•„í„°ë§ (ì—°ë„ & ë¶€ì„œ ì¶”ì¶œ)
        # ------------------------------------------------------------
        if filters is None:
            filters = {}

        # (1) ì—°ë„ ì¶”ì¶œ (2000~2030)
        year_match = re.search(r'(20[0-3]\d)', query)
        # ì‚¬ìš©ìê°€ ì‚¬ì´ë“œë°”ì—ì„œ ì—°ë„ë¥¼ ì§€ì •í•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ì¿¼ë¦¬ ê¸°ë°˜ í•„í„° ì ìš©
        if year_match and "year" not in filters:
            filters["year"] = int(year_match.group(1))
            print(f"ğŸ•µï¸â€â™‚ï¸ [Auto-Filter] ì—°ë„ ê°ì§€: {filters['year']}")

        # (2) ë¶€ì„œ ì¶”ì¶œ (ì„¤ê³„ì²˜, êµ¬ì¡°ë¬¼ì²˜ ë“± 'OOì²˜' íŒ¨í„´)
        # ì´ë¯¸ í•„í„°ì— ì—†ìœ¼ë©´ ì¿¼ë¦¬ì—ì„œ ì°¾ì•„ì„œ ë„£ìŒ
        if "dept" not in filters:
            dept_match = re.search(r'([ê°€-í£]+ì²˜)', query)
            if dept_match:
                filters["dept"] = dept_match.group(1)
                print(f"ğŸ•µï¸â€â™‚ï¸ [Auto-Filter] ë¶€ì„œ ê°ì§€: {filters['dept']}")

        # ------------------------------------------------------------
        # 2. Pinecone ë²¡í„° ê²€ìƒ‰ (Wide Retrieval)
        # ------------------------------------------------------------
        search_query = extract_search_keywords(query) if use_keyword_extraction else query
        query_vector = self.get_embedding(search_query)
        
        raw_results = []
        # ë‹¤ì–‘í•œ ì—°ë„ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•´ top_kë³´ë‹¤ í›¨ì”¬ ë§ì´ ê°€ì ¸ì˜´ (ìµœì†Œ 5ë°°)
        fetch_k = max(top_k * 5, 50) 
        
        if not namespaces:
            try:
                stats = self.index.describe_index_stats()
                namespaces = list(stats.get("namespaces", {}).keys()) or [""]
            except: namespaces = [""]
        
        for ns in namespaces:
            try:
                search_params = {
                    "vector": query_vector,
                    "top_k": fetch_k,
                    "include_metadata": True
                }
                if ns: search_params["namespace"] = ns
                if filters: search_params["filter"] = filters # ì—°ë„/ë¶€ì„œ í•„í„° ì ìš©
                
                results = self.index.query(**search_params)
                
                for match in results.get("matches", []):
                    raw_results.append({
                        "id": match["id"],
                        "score": match["score"],
                        "namespace": ns,
                        "metadata": match.get("metadata", {})
                    })
            except: continue

        # ------------------------------------------------------------
        # 3. í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ë¶€ìŠ¤íŒ… (Lexical Re-ranking)
        # ------------------------------------------------------------
        clean_q = re.sub(r"[^\w\s]", " ", query)
        query_words = [w for w in clean_q.split() if len(w) >= 2]
        
        # 'ê°œì„ ', 'ì ìš©', 'í‘œ' ê´€ë ¨ í‚¤ì›Œë“œëŠ” ì •ë‹µì¼ í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ ì¶”ê°€ ê°€ì‚°ì 
        bonus_keywords = ["ê°œì„ ", "ì ìš©", "ê²€í† ", "ê²°ê³¼", "í‘œ"]

        for doc in raw_results:
            title = doc["metadata"].get("title", "")
            text = doc["metadata"].get("text", "")
            full_text = (title * 2) + " " + text
            
            match_score = 0
            
            # (1) ì§ˆë¬¸ ë‹¨ì–´ ë§¤ì¹­
            for word in query_words:
                if word in full_text: match_score += 0.05
            
            # (2) êµ¬ë¬¸ ë§¤ì¹­ (ê°•ë ¥)
            if len(query_words) >= 2:
                for i in range(len(query_words)-1):
                    phrase = f"{query_words[i]} {query_words[i+1]}"
                    if phrase in full_text: match_score += 0.3
            
            # (3) ì •ë‹µ ì‹œê·¸ë„ ë³´ë„ˆìŠ¤
            for bk in bonus_keywords:
                if bk in full_text: match_score += 0.05

            doc["score"] += match_score
            doc["keyword_matches"] = int(match_score * 10)

        # ------------------------------------------------------------
        # 4. ğŸ”¥ [í•µì‹¬] ì—°ë„ë³„ ì¿¼í„°ì œ ì ìš© (Diversity Strategy)
        # ------------------------------------------------------------
        # ë¬¸ì„œë¥¼ ì—°ë„ë³„ë¡œ ê·¸ë£¹í™”
        docs_by_year = defaultdict(list)
        for doc in raw_results:
            y = doc["metadata"].get("year", "Unknown")
            docs_by_year[y].append(doc)
        
        final_results = []
        selected_ids = set()

        # (1) ê° ì—°ë„ë³„ë¡œ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ 2ê°œ ë¬´ì¡°ê±´ í™•ë³´
        # ì—°ë„ ì—­ìˆœ(ìµœì‹ ìˆœ)ìœ¼ë¡œ ìˆœíšŒ
        sorted_years = sorted(docs_by_year.keys(), reverse=True)
        
        for year in sorted_years:
            # í•´ë‹¹ ì—°ë„ ë¬¸ì„œë“¤ì„ ì ìˆ˜ìˆœ ì •ë ¬
            docs_by_year[year].sort(key=lambda x: x["score"], reverse=True)
            
            # ìƒìœ„ 2ê°œ ì¶”ì¶œ (ìˆìœ¼ë©´)
            top_2_docs = docs_by_year[year][:2]
            for doc in top_2_docs:
                final_results.append(doc)
                selected_ids.add(doc["id"])
        
        # (2) ë‚¨ì€ ê³µê°„(top_k) ì±„ìš°ê¸°
        # ì „ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬, ì•„ì§ ì„ íƒ ì•ˆ ëœ ê³ ë“ì  ë¬¸ì„œ ì¶”ê°€
        raw_results.sort(key=lambda x: x["score"], reverse=True)
        
        for doc in raw_results:
            if len(final_results) >= top_k:
                break
            if doc["id"] not in selected_ids:
                final_results.append(doc)
                selected_ids.add(doc["id"])
        
        # (3) ìµœì¢… ì •ë ¬ (LLMì—ê²ŒëŠ” ì ìˆ˜ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì£¼ëŠ” ê²ƒì´ ì¢‹ìŒ)
        final_results.sort(key=lambda x: x["score"], reverse=True)
        
        return final_results
    
    def build_context(self, results: List[Dict], max_chunks: int = 10) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        context_parts = []
        
        for i, doc in enumerate(results[:max_chunks], 1):
            meta = doc["metadata"]
            score = doc["score"]
            
            code = meta.get("code", "N/A")
            date = meta.get("date", "N/A")
            title = meta.get("title", "ì œëª© ì—†ìŒ")
            dept = meta.get("dept", "N/A")
            year = meta.get("year", "N/A")
            category = meta.get("category", "N/A")
            
            raw_text = meta.get("text", "")
            text = clean_text_for_display(raw_text)
            
            context_parts.append(
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ğŸ“„ [ë¬¸ì„œ {i}] ìœ ì‚¬ë„: {score:.4f}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"â€¢ ì½”ë“œ: {code}\n"
                f"â€¢ ë‚ ì§œ: {date}\n"
                f"â€¢ ë¶€ì„œ: {dept}\n"
                f"â€¢ ì—°ë„: {year}\n"
                f"â€¢ ì œëª©: {title}\n"
                f"â€¢ ë¶„ë¥˜: {category}\n"
                f"\n[ë³¸ë¬¸ ë‚´ìš©]\n{text}\n"
            )
        
        return "\n\n".join(context_parts)
    
    def generate_response_streaming(self, query: str, context: str, 
                                     model: str, placeholder) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±"""
        
        system_prompt = get_system_prompt()        
        user_prompt = get_user_prompt(query, context)

        try:
            stream = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                # ğŸ”¥ğŸ”¥ğŸ”¥ [í•µì‹¬ ìˆ˜ì •: ì¼ê´€ì„± ê°•ì œ ì„¤ì •] ğŸ”¥ğŸ”¥ğŸ”¥
                temperature=0.0,  # ì°½ì˜ì„± 0 (ê°€ì¥ í™•ë¥  ë†’ì€ ë‹¨ì–´ë§Œ ì„ íƒ)
                top_p=0.1,        # í™•ë¥  ë¶„í¬ ê¼¬ë¦¬ ìë¥´ê¸° (ì´ìƒí•œ ë‹¨ì–´ ì„ íƒ ë°©ì§€)
                seed=12345,       # ëœë¤ ì‹œë“œ ê³ ì • (í•­ìƒ ê°™ì€ ê²°ê³¼ë¥¼ ë‚´ë„ë¡ ê°•ì œ)
                stream=True
            )
            
            response_text = ""
            for chunk in stream:
                if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                    response_text += chunk.choices[0].delta.content
                    placeholder.markdown(response_text + "â–Œ")
            
            placeholder.markdown(response_text)
            return response_text
            
        except Exception as e:
            placeholder.error(f"âŒ LLM í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return ""
    
    def get_index_stats(self) -> Dict:
        """ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ"""
        try:
            return self.index.describe_index_stats()
        except Exception as e:
            return {"error": str(e)}


# =========================
# ì°¸ì¡° ë¬¸ì„œ ë Œë”ë§
# =========================
def render_source_card(doc: Dict, rank: int, msg_idx: int = 0):
    """ì°¸ì¡° ë¬¸ì„œ ì¹´ë“œ ë Œë”ë§"""
    meta = doc["metadata"]
    score = doc["score"]
    
    code = meta.get("code", "N/A")
    title = meta.get("title", "ì œëª© ì—†ìŒ")
    date = meta.get("date", "")
    dept = meta.get("dept", "")
    year = meta.get("year", "")
    category = meta.get("category", "")
    
    raw_text = meta.get("text", "")
    cleaned_text = clean_text_for_display(raw_text)
    
    preview_length = 500
    preview_text = cleaned_text[:preview_length]
    has_more = len(cleaned_text) > preview_length
    
    unique_key = f"m{msg_idx}_r{rank}_{doc['id'][:8]}"
    
    # ğŸ”¥ í‚¤ì›Œë“œ ë§¤ì¹­ ì •ë³´ í‘œì‹œ
    keyword_info = ""
    if "keyword_matches" in doc and doc["keyword_matches"] > 0:
        keyword_info = f" ğŸ”+{doc['keyword_matches']}"
    
    with st.expander(f"ğŸ“„ [{rank}] {code} - {title} (ìœ ì‚¬ë„: {score:.4f}){keyword_info}", expanded=False):
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown(f"**ì½”ë“œ:** `{code}`")
        with col2:
            st.markdown(f"**ë‚ ì§œ:** {date}")
        with col3:
            st.markdown(f"**ë¶€ì„œ:** {dept}")
        with col4:
            st.markdown(f"**ì—°ë„:** {year}")
        
        if category and category != "N/A":
            st.markdown(f"**ë¶„ë¥˜:** {category}")
        
        st.markdown("---")
        st.markdown("**ğŸ“ ë³¸ë¬¸ ë‚´ìš©:**")
        st.markdown(preview_text)
        
        if has_more:
            show_full_key = f"show_full_{unique_key}"
            if show_full_key not in st.session_state:
                st.session_state[show_full_key] = False
            
            if st.button(f"ğŸ“– ì „ì²´ ë³´ê¸°", key=f"btn_{unique_key}"):
                st.session_state[show_full_key] = not st.session_state[show_full_key]
            
            if st.session_state[show_full_key]:
                st.markdown("---")
                st.markdown("**[ì „ì²´ ë‚´ìš©]**")
                st.markdown(cleaned_text)


def render_source_summary(results: List[Dict]):
    """ì°¸ì¡° ë¬¸ì„œ ìš”ì•½ í‘œì‹œ"""
    if not results:
        return
    
    st.markdown("**ğŸ“š ì°¸ì¡° ë¬¸ì„œ ëª©ë¡:**")
    
    summary_lines = []
    for i, doc in enumerate(results, 1):
        meta = doc["metadata"]
        code = meta.get("code", "N/A")
        title = meta.get("title", "ì œëª© ì—†ìŒ")
        date = meta.get("date", "")
        score = doc["score"]
        
        keyword_info = ""
        if "keyword_matches" in doc and doc["keyword_matches"] > 0:
            keyword_info = f" ğŸ”+{doc['keyword_matches']}"
        
        summary_lines.append(f"{i}. `{code}` - {title} ({date}) [ìœ ì‚¬ë„: {score:.3f}]{keyword_info}")
    
    st.markdown("\n".join(summary_lines))


# =========================
# ìë™ ìŠ¤í¬ë¡¤ í•¨ìˆ˜
# =========================
def scroll_to_bottom():
    """JavaScriptë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ í•˜ë‹¨ìœ¼ë¡œ ìŠ¤í¬ë¡¤"""
    st.markdown(
        """
        <script>
            window.scrollTo({
                top: document.body.scrollHeight,
                behavior: 'smooth'
            });
        </script>
        """,
        unsafe_allow_html=True
    )


# =========================
# ë©”ì¸ ì•±
# =========================
def main():
    st.title("ğŸ—ï¸ ì„¤ê³„ì‹¤ë¬´ì§€ì¹¨ AI ê²€ìƒ‰")
    st.caption("Pinecone RAG + GPT ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ v3 + Lexical Re-rank")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "rag" not in st.session_state:
        st.session_state.rag = PineconeRAG()
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "initialized" not in st.session_state:
        st.session_state.initialized = False
    if "pending_query" not in st.session_state:
        st.session_state.pending_query = None
    
    rag = st.session_state.rag
    
    # ğŸ”¥ ìë™ ì´ˆê¸°í™” (ì•± ì‹œì‘ì‹œ í•œ ë²ˆë§Œ)
    if not st.session_state.initialized:
        with st.spinner("ğŸ”Œ API ìë™ ì—°ê²° ì¤‘..."):
            if rag.init_clients():
                st.session_state.initialized = True
                st.success("âœ… API ì—°ê²° ì™„ë£Œ!")
            else:
                st.error("âŒ API ì—°ê²° ì‹¤íŒ¨. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # =========================
    # ì‚¬ì´ë“œë°”
    # =========================
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ì—°ê²° ìƒíƒœ
        if st.session_state.initialized:
            st.success("âœ… API ì—°ê²°ë¨")
            
            # ì¬ì—°ê²° ë²„íŠ¼
            if st.button("ğŸ”„ ì¬ì—°ê²°"):
                with st.spinner("ì¬ì—°ê²° ì¤‘..."):
                    if rag.init_clients():
                        st.success("âœ… ì¬ì—°ê²° ì„±ê³µ!")
                    else:
                        st.error("âŒ ì¬ì—°ê²° ì‹¤íŒ¨")
        else:
            st.error("âŒ API ë¯¸ì—°ê²°")
            if st.button("ğŸ”Œ ìˆ˜ë™ ì—°ê²°", type="primary"):
                with st.spinner("ì—°ê²° ì¤‘..."):
                    if rag.init_clients():
                        st.session_state.initialized = True
                        st.success("âœ… ì—°ê²° ì„±ê³µ!")
                    else:
                        st.error("âŒ ì—°ê²° ì‹¤íŒ¨")
        
        if st.session_state.initialized:
            st.divider()
            
            # ì¸ë±ìŠ¤ ì •ë³´
            stats = rag.get_index_stats()
            if "error" not in stats:
                total_vectors = stats.get("total_vector_count", 0)
                st.metric("ğŸ“Š ì´ ë²¡í„° ìˆ˜", f"{total_vectors:,}")
                
                namespaces = stats.get("namespaces", {})
                if namespaces:
                    with st.expander("ğŸ“ Namespace ìƒì„¸"):
                        for ns, info in namespaces.items():
                            display_name = rag.namespace_map.get(ns, ns) or "(ê¸°ë³¸)"
                            count = info.get("vector_count", 0)
                            st.text(f"{display_name}: {count:,}ê°œ")
            
            st.divider()
            
            # Namespace ì„ íƒ
            st.subheader("ğŸ“ Namespace")
            ns_options = rag.get_namespaces()
            
            select_all = st.checkbox("ì „ì²´ ì„ íƒ", value=True)
            
            if select_all:
                selected_namespaces = list(ns_options.values())
                st.info(f"âœ… ëª¨ë“  namespaceì—ì„œ ê²€ìƒ‰ ({len(selected_namespaces)}ê°œ)")
            else:
                selected_displays = st.multiselect(
                    "ê²€ìƒ‰í•  namespace",
                    options=list(ns_options.keys()),
                    default=list(ns_options.keys())[:1]
                )
                selected_namespaces = [ns_options[d] for d in selected_displays]
            
            st.divider()
            
            # LLM ì„¤ì •
            st.subheader("ğŸ¤– LLM ì„¤ì •")
            model_options = {
                "GPT-4o-mini (ê¸°ë³¸, ì €ë¹„ìš©)": "gpt-4o-mini",
                "GPT-4o (ê³ í’ˆì§ˆ)": "gpt-4o",
                "GPT-4-turbo": "gpt-4-turbo",
            }
            selected_model_name = st.selectbox("ëª¨ë¸", list(model_options.keys()))
            selected_model = model_options[selected_model_name]
            
            custom_model = st.text_input("ì»¤ìŠ¤í…€ ëª¨ë¸ëª…", placeholder="ì˜ˆ: gpt-4.5-preview")
            if custom_model.strip():
                selected_model = custom_model.strip()
            
            st.divider()
            
           
            # ê²€ìƒ‰ ì„¤ì •
            st.subheader("ğŸ” ê²€ìƒ‰ ì„¤ì •")
            top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 3, 30, 10,
                             help="ìµœì¢… ë°˜í™˜ ë¬¸ì„œ ìˆ˜ (ë‚´ë¶€ì ìœ¼ë¡œ 5ë°° ë§ì´ ê²€ìƒ‰)")
            context_chunks = st.slider("LLM ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ìˆ˜", 3, 30, 10,
                                       help="LLMì— ì „ë‹¬í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜")
            
            use_keyword_extraction = st.checkbox("í‚¤ì›Œë“œ ì¶”ì¶œ ì‚¬ìš©", value=True,
                                                  help="ë¶ˆìš©ì–´ ì œê±°ë¡œ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ")
            
            st.divider()
            
            # í•„í„° ì„¤ì •
            st.subheader("ğŸ·ï¸ í•„í„° (ì„ íƒ)")
            filter_dept = st.text_input("ë¶€ì„œ", placeholder="ì˜ˆ: ì„¤ê³„ì²˜")
            filter_year = st.number_input("ì—°ë„ (0=ì „ì²´)", min_value=0, max_value=2030, value=0)
            
            st.divider()
            
            # ëŒ€í™” ì´ˆê¸°í™”
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
                st.session_state.messages = []
                st.session_state.pending_query = None
                st.rerun()
            
       
    # -------------------------
    # ì˜ˆì œ ì§ˆë¬¸ ë°ì´í„° (ì—°ë„ë³„)
    # -------------------------
    EXAMPLES_BY_YEAR = {
        2024: [
            "ë¼ì´ë‹¤ ì¸¡ëŸ‰ì„ ë‹¤ì‹œ í•´ì•¼í•˜ëŠ” ê²½ìš°ëŠ”?",
            "ì„¤ê³„ í•˜ìì±…ì„ê¸°ê°„ ê´€ë¦¬ëŠ” ì–´ë–¤ ë¶€ì„œ?",
            "ì£¼ë¯¼ì„¤ëª…íšŒì—ì„œ BIM í™œìš© ë°©ë²•ì€?",
            "íƒ€ë‹¹ì„± ë° ê¸°ë³¸ì„¤ê³„ ê¸°ê°„ì€?",
            "ë‚´ë¦¬ë§‰ ì¢Œì¸¡ ê³¡ì„ ë¶€ ê³¡ì„ ë°˜ê²½ì€?",
            "ê°€ë„, ê°€êµ ì„¤ì¹˜ ê¸°ì¤€ì„ ì•Œë ¤ì¤˜",
            "ì§€í•˜ì°¨ë„ ë°°ìˆ˜ ìˆ˜ë°©ì²´ê³„ í‘œì¤€ì•ˆì€?",
            "ì œì„¤ì—¼í•´ ìœ„í—˜êµ¬ê°„ì„ ì•Œë ¤ì¤˜",
            "ë‚˜ë“¤ëª© ì¤‘ì•™ë¶„ë¦¬ëŒ€ ë°©í˜¸ë“±ê¸‰ì€?",
        ],
        2023: [
            "ê³ ì†ë„ë¡œ ê±´ì„¤ ê´€ë ¨ ë¶€ë‹´ê¸ˆì€?",
            "í•˜ì´íŒ¨ìŠ¤ ë‚˜ë“¤ëª© ì„¤ê³„ ê¸°ê°„ì€?",
            "ì•ˆì „ê´€ë¦¬ë¹„ ê°„ì ‘ê³µì‚¬ë¹„ ì ìš©ì€?",
            "ë°°ìˆ˜ì„± í¬ì¥ ì ìš© ëŒ€ìƒ êµ¬ê°„ì€?",
            "ì—¬êµ´ëŸ‰ ì‚°ì¶œê¸°ì¤€ì„ ì•Œë ¤ì¤˜",
            "í„°ë„ íìˆ˜ì²˜ë¦¬ì‹œì„¤ ê³„ìƒê¸°ì¤€ì€?",
            "ì„¤ê³„ ì•ˆì „ì„± ê²€í†  ë°©ë²•ì€?",
            "ì„¤ê³„ë‹¨ê³„ë³„ ì£¼ë¯¼ì„¤ëª…íšŒ ì‹œê¸°ëŠ”?",
            "ì§€ì ì¤‘ì²©ë„ ì‘ì„± ì˜ë¢° ì‹œê¸°ëŠ”?",
            "í™•ì¥êµ¬ê°„ ë‚´ ì œí•œì†ë„ëŠ”?",
            "ì ê²€ ìŠ¹ê°•ì‹œì„¤ ì„¤ì¹˜ ê¸°ì¤€ì€?",
        ],
        2017: [
            "ê²½ê´€ì„¤ê³„ ëŒ€ìƒ ì‹œì„¤ë¬¼ì„ ì•Œë ¤ì¤˜",
            "ì¶•ì¤‘ì°¨ë¡œë¥¼ ìŠ¤ë§ˆíŠ¸í†¨ë§ ì°¨ë¡œë¡œ ì „í™˜ì‹œ ì„¤ê³„ê¸°ì¤€ì€?",
            "ê³ ì†ë„ë¡œ ì„¤ê³„ì‹œ ì„¤ê³„ê°•ìš°ê°•ë„ë¥¼ ì–´ë–»ê²Œ ì ìš©í•´ì•¼ í•˜ëŠ”ì§€ ì•Œë ¤ì¤˜",
            "êµëŸ‰ ê³ ì •ì‹ ì ê²€ì‹œì„¤ ì„¤ì¹˜ê¸°ì¤€ì„ ì•Œë ¤ì¤˜",
            "êµë©´ ë°°ìˆ˜êµ¬ ì„¤ì¹˜ê°„ê²© ê¸°ì¤€ì„ ì•Œë ¤ì¤˜",
            "êµëŸ‰í•˜ë¶€ ê°€ë“œíœ€ìŠ¤ ì„¤ì¹˜ ê¸°ì¤€ì€?",
            "í•˜ì´ë¸Œë¦¬ë“œ ê±°ë”ì˜ ì •ì˜ë¥¼ ì•Œë ¤ì¤˜",
            "ì½˜í¬ë¦¬íŠ¸ í¬ì¥ ì¤„ëˆˆ ì„¤ì¹˜ ê¸°ì¤€ì„ ì•Œë ¤ì¤˜",
            "í„°ë„ ìš”ì² í¬ì¥ ì„¤ì¹˜ ê¸°ì¤€ì„ ì•Œë ¤ì¤˜",
        ],
    }

    # íƒ­ ìˆœì„œ(ì›í•˜ëŠ” ì—°ë„ë§Œ ë„£ìœ¼ë©´ ë¨)
    YEARS = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017]

    st.divider()
    st.sidebar.markdown("### ğŸ’¡ ì˜ˆì œ ì§ˆë¬¸")

    for year in [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017]:
        with st.sidebar.expander(f"ğŸ“… {year}ë…„", expanded=(year == 2017)):
            examples = EXAMPLES_BY_YEAR.get(year, [])
            c1, c2 = st.columns(2)
            for i, q in enumerate(examples):
                with (c1 if i % 2 == 0 else c2):
                    if st.button(q, key=f"ex_{year}_{i}", use_container_width=True):
                        st.session_state.pending_query = q


        
    # =========================
    # ë©”ì¸ ì˜ì—­
    # =========================
    if not st.session_state.initialized:
        st.info("â³ API ì—°ê²° ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        st.stop()
    
    # =========================
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    # =========================
    for msg_idx, msg in enumerate(st.session_state.messages):
        if msg["role"] == "user":
            with st.chat_message("user"):
                st.markdown(msg["content"])
        else:
            with st.chat_message("assistant"):
                st.markdown(msg["content"])
                if "sources" in msg and msg["sources"]:
                    with st.expander("ğŸ“š ì°¸ì¡° ë¬¸ì„œ", expanded=False):
                        render_source_summary(msg["sources"])
                        st.markdown("---")
                        for i, doc in enumerate(msg["sources"], 1):
                            render_source_card(doc, i, msg_idx=msg_idx)
    
    # =========================
    # ğŸ”¥ ì…ë ¥ ì²˜ë¦¬ (pending_query ìš°ì„ )
    # =========================
    query = None
    
    # 1. pending_queryê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if st.session_state.pending_query:
        query = st.session_state.pending_query
        st.session_state.pending_query = None
    
    # 2. chat_input í•­ìƒ í‘œì‹œ
    chat_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    if chat_query and not query:
        query = chat_query
    
    # =========================
    # ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬
    # =========================
    if query:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": query})
        
        with st.chat_message("user"):
            st.markdown(query)
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ
        with st.chat_message("assistant"):
            # í•„í„° êµ¬ì„±
            filters = {}
            if filter_dept:
                filters["dept"] = filter_dept
            if filter_year > 0:
                filters["year"] = filter_year
            
            # ê²€ìƒ‰
            with st.spinner("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘... (50ê°œ ê²€ìƒ‰ â†’ ì¬ì •ë ¬)"):
                t0 = time.time()
                results = rag.search(
                    query=query,
                    top_k=top_k,
                    namespaces=selected_namespaces,
                    filters=filters if filters else None,
                    use_keyword_extraction=use_keyword_extraction
                )
                search_time = time.time() - t0
            
            if not results:
                st.warning("âš ï¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                response = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ì£¼ì„¸ìš”."
                used_sources = []
            else:
                # ğŸ”¥ í‚¤ì›Œë“œ ë§¤ì¹­ ì •ë³´ í‘œì‹œ
                keyword_boosted = sum(1 for doc in results if doc.get("keyword_matches", 0) > 0)
                st.caption(f"âœ… {len(results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ ({search_time:.2f}ì´ˆ) | í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ…: {keyword_boosted}ê°œ")
                
                # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                context = rag.build_context(results, max_chunks=context_chunks)
                
                # LLM ì‘ë‹µ ìƒì„±
                placeholder = st.empty()
                response = rag.generate_response_streaming(
                    query, context, selected_model, placeholder,
                )
                
                # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
                with st.expander("ğŸ“š ì°¸ì¡° ë¬¸ì„œ", expanded=False):
                    render_source_summary(results)
                    st.markdown("---")
                    current_msg_idx = len(st.session_state.messages)
                    for i, doc in enumerate(results, 1):
                        render_source_card(doc, i, msg_idx=current_msg_idx)
                
                used_sources = results
        
        # ë©”ì‹œì§€ ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "sources": used_sources
        })
        
        # ğŸ”¥ ìë™ ìŠ¤í¬ë¡¤ (ë‹µë³€ í›„)
        scroll_to_bottom()
        
        # ğŸ”¥ ì¦‰ì‹œ ë¦¬ë Œë”ë§ (ì…ë ¥ì°½ ìœ ì§€)
        st.rerun()


# =========================
# ì‹¤í–‰
# =========================
if __name__ == "__main__":
    if not OPENAI_AVAILABLE:
        st.error("âŒ openai íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜")
        st.code("pip install openai python-dotenv")
        st.stop()
    if not PINECONE_AVAILABLE:
        st.error("âŒ pinecone íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜")
        st.code("pip install pinecone")
        st.stop()
    
    main()